{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Introduction \n","\n","This notebook presents a comprehensive guide to fine-tuning Facebook's BART (Bidirectional and Auto-Regressive Transformers) model for the task of summarizing chat conversations. \n","\n","The notebook is structured to provide a seamless and educative experience in applying advanced NLP techniques for practical applications.\n","\n","The model fine-tuning utilizes three distinct datasets:\n","\n","1. **DialogSum Dataset:** A specialized dataset for dialogue summarization, offering diverse conversational examples.\n","\n","2. **SAMSUM Dataset by Samsung:** This dataset comprises scripted chat conversations with associated human-written summaries, providing a rich ground for training and validating summarization models.\n","\n","3. **Custom Dataset:** A personally curated dataset, designed to include a variety of chat styles and topics, ensuring robustness and versatility in the model's performance.\n"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T18:09:47.093763Z","iopub.status.busy":"2023-11-16T18:09:47.092791Z","iopub.status.idle":"2023-11-16T18:09:47.098482Z","shell.execute_reply":"2023-11-16T18:09:47.097600Z","shell.execute_reply.started":"2023-11-16T18:09:47.093724Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\wjdrb\\vscode_code\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["# Importing necessary libraries\n","import json\n","import pandas as pd\n","import random\n","from transformers import BartTokenizer, BartForConditionalGeneration, Trainer, TrainingArguments\n","from torch.utils.data import Dataset\n","import torch"]},{"cell_type":"markdown","metadata":{},"source":["We will install rogue score to evaluate the summaries generated by the model."]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T16:23:56.900828Z","iopub.status.busy":"2023-11-16T16:23:56.900262Z","iopub.status.idle":"2023-11-16T16:24:13.423768Z","shell.execute_reply":"2023-11-16T16:24:13.422796Z","shell.execute_reply.started":"2023-11-16T16:23:56.900799Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: rouge_score in c:\\users\\wjdrb\\vscode_code\\venv\\lib\\site-packages (0.1.2)\n","Requirement already satisfied: absl-py in c:\\users\\wjdrb\\vscode_code\\venv\\lib\\site-packages (from rouge_score) (2.1.0)\n","Requirement already satisfied: nltk in c:\\users\\wjdrb\\vscode_code\\venv\\lib\\site-packages (from rouge_score) (3.8.1)\n","Requirement already satisfied: numpy in c:\\users\\wjdrb\\vscode_code\\venv\\lib\\site-packages (from rouge_score) (1.26.4)\n","Requirement already satisfied: six>=1.14.0 in c:\\users\\wjdrb\\vscode_code\\venv\\lib\\site-packages (from rouge_score) (1.16.0)\n","Requirement already satisfied: click in c:\\users\\wjdrb\\vscode_code\\venv\\lib\\site-packages (from nltk->rouge_score) (8.1.7)\n","Requirement already satisfied: joblib in c:\\users\\wjdrb\\vscode_code\\venv\\lib\\site-packages (from nltk->rouge_score) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in c:\\users\\wjdrb\\vscode_code\\venv\\lib\\site-packages (from nltk->rouge_score) (2023.12.25)\n","Requirement already satisfied: tqdm in c:\\users\\wjdrb\\vscode_code\\venv\\lib\\site-packages (from nltk->rouge_score) (4.66.2)\n","Requirement already satisfied: colorama in c:\\users\\wjdrb\\vscode_code\\venv\\lib\\site-packages (from click->nltk->rouge_score) (0.4.6)\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip is available: 24.0 -> 24.1.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]}],"source":["!pip install rouge_score"]},{"cell_type":"markdown","metadata":{},"source":["# 1. DialogSum dataset"]},{"cell_type":"markdown","metadata":{},"source":["### Defining functions to read and clean the dataset"]},{"cell_type":"markdown","metadata":{},"source":["**Note**\n","\n","- To enhance the model's applicability to real-world scenarios, the original DialogSum dataset was modified by replacing generic placeholders 'Person1' and 'Person2' with a diverse list of names. \n","- This adaptation ensures that the model is trained on data more representative of actual conversation patterns, thereby improving its practical utility and performance in real-world applications."]},{"cell_type":"markdown","metadata":{},"source":["### Training set of DialogSum"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T16:24:13.443246Z","iopub.status.busy":"2023-11-16T16:24:13.442841Z","iopub.status.idle":"2023-11-16T16:24:15.273142Z","shell.execute_reply":"2023-11-16T16:24:15.272178Z","shell.execute_reply.started":"2023-11-16T16:24:13.443214Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dialogue</th>\n","      <th>summary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Ursula: Hi, Mr. Smith. I'm Doctor Hawkins. Why...</td>\n","      <td>Mr. Smith's getting a check-up, and Doctor Haw...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Queenie: Hello Mrs. Parker, how have you been?...</td>\n","      <td>Mrs Parker takes Ricky for his vaccines. Dr. P...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Bob: Excuse me, did you see a set of keys?\\nSe...</td>\n","      <td>Bob's looking for a set of keys and asks for S...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Zelda: Why didn't you tell me you had a girlfr...</td>\n","      <td>Zelda's angry because Victor didn't tell Zelda...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Samuel: Watsup, ladies! Y'll looking'fine toni...</td>\n","      <td>Malik invites Nikki to dance. Nikki agrees if ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>12455</th>\n","      <td>Diana: Excuse me. You are Mr. Green from Manch...</td>\n","      <td>Tan Ling picks Mr. Green up who is easily reco...</td>\n","    </tr>\n","    <tr>\n","      <th>12456</th>\n","      <td>Samuel: Mister Ewing said we should show up at...</td>\n","      <td>Samuel and Bob plan to take the underground to...</td>\n","    </tr>\n","    <tr>\n","      <th>12457</th>\n","      <td>Edward: How can I help you today?\\nAaron: I wo...</td>\n","      <td>Aaron rents a small car for 5 days with the he...</td>\n","    </tr>\n","    <tr>\n","      <th>12458</th>\n","      <td>Kylie: You look a bit unhappy today. What's up...</td>\n","      <td>Zach's mom lost her job. Zach hopes mom won't ...</td>\n","    </tr>\n","    <tr>\n","      <th>12459</th>\n","      <td>Ophelia: Mom, I'm flying to visit uncle Lee's ...</td>\n","      <td>Ophelia asks for Olivia's idea of packing the ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>12460 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                dialogue  \\\n","0      Ursula: Hi, Mr. Smith. I'm Doctor Hawkins. Why...   \n","1      Queenie: Hello Mrs. Parker, how have you been?...   \n","2      Bob: Excuse me, did you see a set of keys?\\nSe...   \n","3      Zelda: Why didn't you tell me you had a girlfr...   \n","4      Samuel: Watsup, ladies! Y'll looking'fine toni...   \n","...                                                  ...   \n","12455  Diana: Excuse me. You are Mr. Green from Manch...   \n","12456  Samuel: Mister Ewing said we should show up at...   \n","12457  Edward: How can I help you today?\\nAaron: I wo...   \n","12458  Kylie: You look a bit unhappy today. What's up...   \n","12459  Ophelia: Mom, I'm flying to visit uncle Lee's ...   \n","\n","                                                 summary  \n","0      Mr. Smith's getting a check-up, and Doctor Haw...  \n","1      Mrs Parker takes Ricky for his vaccines. Dr. P...  \n","2      Bob's looking for a set of keys and asks for S...  \n","3      Zelda's angry because Victor didn't tell Zelda...  \n","4      Malik invites Nikki to dance. Nikki agrees if ...  \n","...                                                  ...  \n","12455  Tan Ling picks Mr. Green up who is easily reco...  \n","12456  Samuel and Bob plan to take the underground to...  \n","12457  Aaron rents a small car for 5 days with the he...  \n","12458  Zach's mom lost her job. Zach hopes mom won't ...  \n","12459  Ophelia asks for Olivia's idea of packing the ...  \n","\n","[12460 rows x 2 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Path to JSONL file\n","train_file_path = '/kaggle/input/dialogue-chat/dialogsum.train.jsonl'\n","\n","# Reading the JSONL file and creating a DataFrame\n","train_df1 = read_jsonl_to_dataframe(train_file_path)\n","\n","# Replacing names in the DataFrame\n","train_df1 = replace_names(train_df1, names_list)\n","\n","# Displaying the first few rows of the DataFrame with replaced names\n","train_df1"]},{"cell_type":"markdown","metadata":{},"source":["### Validation set of DialogSum"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T16:24:15.274977Z","iopub.status.busy":"2023-11-16T16:24:15.274505Z","iopub.status.idle":"2023-11-16T16:24:15.369578Z","shell.execute_reply":"2023-11-16T16:24:15.368720Z","shell.execute_reply.started":"2023-11-16T16:24:15.274939Z"},"trusted":true},"outputs":[],"source":["from datasets import load_dataset\n","\n","billsum = load_dataset(\"Kyudan/GTNT_8.25M\")"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["split_dataset = billsum['train'].train_test_split(test_size=0.2)\n","\n","# train과 test 데이터셋 확인\n","train_dataset = split_dataset['train']\n","test_dataset = split_dataset['test']"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T16:24:15.927105Z","iopub.status.busy":"2023-11-16T16:24:15.926279Z","iopub.status.idle":"2023-11-16T16:24:24.205219Z","shell.execute_reply":"2023-11-16T16:24:24.204366Z","shell.execute_reply.started":"2023-11-16T16:24:15.927068Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\wjdrb\\vscode_code\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\wjdrb\\.cache\\huggingface\\hub\\models--facebook--bart-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n","To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n","  warnings.warn(message)\n"]}],"source":["from transformers import BartTokenizer, BartForConditionalGeneration\n","\n","# Initialize the tokenizer for BART\n","# 'facebook/bart-base' is a pretrained model identifier\n","# The tokenizer is responsible for converting text input into tokens that the model can understand\n","tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n","\n","# Initialize the BART model for conditional generation\n","# This model is used for tasks like summarization where the output is conditional on the input text\n","# The model is loaded with pretrained weights from 'facebook/bart-base'\n","model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T16:24:24.206673Z","iopub.status.busy":"2023-11-16T16:24:24.206371Z","iopub.status.idle":"2023-11-16T16:24:24.211222Z","shell.execute_reply":"2023-11-16T16:24:24.210343Z","shell.execute_reply.started":"2023-11-16T16:24:24.206647Z"},"trusted":true},"outputs":[],"source":["def preprocess_function(examples):\n","    # Prepends the string \"summarize: \" to each document in the 'text' field of the input examples.\n","    # This is done to instruct the T5 model on the task it needs to perform, which in this case is summarization.\n","    inputs = [\"translate: \" + doc for doc in examples[\"NT\"]]\n","\n","    # Tokenizes the prepended input texts to convert them into a format that can be fed into the T5 model.\n","    # Sets a maximum token length of 1024, and truncates any text longer than this limit.\n","    model_inputs = tokenizer(inputs, max_length=256, truncation=True)\n","\n","    # Tokenizes the 'summary' field of the input examples to prepare the target labels for the summarization task.\n","    # Sets a maximum token length of 128, and truncates any text longer than this limit.\n","    labels = tokenizer(text_target=examples[\"GT\"], max_length=256, truncation=True)\n","\n","    # Assigns the tokenized labels to the 'labels' field of model_inputs.\n","    # The 'labels' field is used during training to calculate the loss and guide model learning.\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","\n","    # Returns the prepared inputs and labels as a single dictionary, ready for training.\n","    return model_inputs"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Map:  29%|██▉       | 1913000/6602527 [07:41<18:51, 4144.51 examples/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tokenized_billsum \u001b[38;5;241m=\u001b[39m \u001b[43msplit_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\wjdrb\\vscode_code\\venv\\Lib\\site-packages\\datasets\\dataset_dict.py:869\u001b[0m, in \u001b[0;36mDatasetDict.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_file_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    866\u001b[0m     cache_file_names \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n\u001b[0;32m    867\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict(\n\u001b[0;32m    868\u001b[0m     {\n\u001b[1;32m--> 869\u001b[0m         k: \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdrop_last_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m            \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_file_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdisable_nullable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_nullable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    888\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    889\u001b[0m     }\n\u001b[0;32m    890\u001b[0m )\n","File \u001b[1;32mc:\\Users\\wjdrb\\vscode_code\\venv\\Lib\\site-packages\\datasets\\arrow_dataset.py:593\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    591\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    592\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 593\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    594\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\wjdrb\\vscode_code\\venv\\Lib\\site-packages\\datasets\\arrow_dataset.py:558\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    551\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    552\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    556\u001b[0m }\n\u001b[0;32m    557\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 558\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    559\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    560\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\wjdrb\\vscode_code\\venv\\Lib\\site-packages\\datasets\\arrow_dataset.py:3105\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3100\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[0;32m   3101\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3102\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[0;32m   3103\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3104\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m-> 3105\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_single\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   3106\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   3107\u001b[0m \u001b[43m                \u001b[49m\u001b[43mshards_done\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n","File \u001b[1;32mc:\\Users\\wjdrb\\vscode_code\\venv\\Lib\\site-packages\\datasets\\arrow_dataset.py:3482\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[0;32m   3478\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   3479\u001b[0m     \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mslice\u001b[39m(i, i \u001b[38;5;241m+\u001b[39m batch_size)\u001b[38;5;241m.\u001b[39mindices(shard\u001b[38;5;241m.\u001b[39mnum_rows)))\n\u001b[0;32m   3480\u001b[0m )  \u001b[38;5;66;03m# Something simpler?\u001b[39;00m\n\u001b[0;32m   3481\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3482\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_same_num_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3486\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3487\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3488\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[0;32m   3489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[0;32m   3490\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3491\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\wjdrb\\vscode_code\\venv\\Lib\\site-packages\\datasets\\arrow_dataset.py:3361\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[1;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[0;32m   3359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[0;32m   3360\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[1;32m-> 3361\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[0;32m   3363\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   3364\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[0;32m   3365\u001b[0m     }\n","Cell \u001b[1;32mIn[6], line 8\u001b[0m, in \u001b[0;36mpreprocess_function\u001b[1;34m(examples)\u001b[0m\n\u001b[0;32m      4\u001b[0m inputs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranslate: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m doc \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m examples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNT\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Tokenizes the prepended input texts to convert them into a format that can be fed into the T5 model.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Sets a maximum token length of 1024, and truncates any text longer than this limit.\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Tokenizes the 'summary' field of the input examples to prepare the target labels for the summarization task.\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Sets a maximum token length of 128, and truncates any text longer than this limit.\u001b[39;00m\n\u001b[0;32m     12\u001b[0m labels \u001b[38;5;241m=\u001b[39m tokenizer(text_target\u001b[38;5;241m=\u001b[39mexamples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGT\u001b[39m\u001b[38;5;124m\"\u001b[39m], max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","File \u001b[1;32mc:\\Users\\wjdrb\\vscode_code\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2945\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2943\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[0;32m   2944\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[1;32m-> 2945\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2946\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2947\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n","File \u001b[1;32mc:\\Users\\wjdrb\\vscode_code\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3032\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[0;32m   3027\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3028\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match batch length of `text_pair`:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3029\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3030\u001b[0m         )\n\u001b[0;32m   3031\u001b[0m     batch_text_or_text_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[1;32m-> 3032\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3033\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3034\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3035\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3036\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3037\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3038\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3039\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3040\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3041\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3042\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3043\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3044\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3045\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3047\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3049\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3050\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3051\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3052\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3053\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[0;32m   3054\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[0;32m   3055\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3072\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3073\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\wjdrb\\vscode_code\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3228\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[0;32m   3218\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[0;32m   3219\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[0;32m   3220\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m   3221\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3225\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3226\u001b[0m )\n\u001b[1;32m-> 3228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3230\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3242\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3245\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3246\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3247\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\wjdrb\\vscode_code\\venv\\Lib\\site-packages\\transformers\\tokenization_utils.py:873\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m     ids, pair_ids \u001b[38;5;241m=\u001b[39m ids_or_pair_ids\n\u001b[1;32m--> 873\u001b[0m first_ids \u001b[38;5;241m=\u001b[39m \u001b[43mget_input_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    874\u001b[0m second_ids \u001b[38;5;241m=\u001b[39m get_input_ids(pair_ids) \u001b[38;5;28;01mif\u001b[39;00m pair_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    875\u001b[0m input_ids\u001b[38;5;241m.\u001b[39mappend((first_ids, second_ids))\n","File \u001b[1;32mc:\\Users\\wjdrb\\vscode_code\\venv\\Lib\\site-packages\\transformers\\tokenization_utils.py:840\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus.<locals>.get_input_ids\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_input_ids\u001b[39m(text):\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 840\u001b[0m         tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_tokens_to_ids(tokens)\n\u001b[0;32m    842\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(text) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mstr\u001b[39m):\n","File \u001b[1;32mc:\\Users\\wjdrb\\vscode_code\\venv\\Lib\\site-packages\\transformers\\tokenization_utils.py:686\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.tokenize\u001b[1;34m(self, text, **kwargs)\u001b[0m\n\u001b[0;32m    684\u001b[0m         tokenized_text\u001b[38;5;241m.\u001b[39mappend(token)\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         tokenized_text\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    687\u001b[0m \u001b[38;5;66;03m# [\"This\", \" is\", \" something\", \"<special_token_1>\", \"else\"]\u001b[39;00m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokenized_text\n","File \u001b[1;32mc:\\Users\\wjdrb\\vscode_code\\venv\\Lib\\site-packages\\transformers\\models\\bart\\tokenization_bart.py:261\u001b[0m, in \u001b[0;36mBartTokenizer._tokenize\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Tokenize a string.\"\"\"\u001b[39;00m\n\u001b[0;32m    260\u001b[0m bpe_tokens \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 261\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    262\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m    263\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbyte_encoder[b] \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m token\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    264\u001b[0m     )  \u001b[38;5;66;03m# Maps all our bytes to unicode strings, avoiding control tokens of the BPE (spaces in our case)\u001b[39;00m\n\u001b[0;32m    265\u001b[0m     bpe_tokens\u001b[38;5;241m.\u001b[39mextend(bpe_token \u001b[38;5;28;01mfor\u001b[39;00m bpe_token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbpe(token)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m))\n","File \u001b[1;32mc:\\Users\\wjdrb\\vscode_code\\venv\\Lib\\site-packages\\regex\\regex.py:338\u001b[0m, in \u001b[0;36mfindall\u001b[1;34m(pattern, string, flags, pos, endpos, overlapped, concurrent, timeout, ignore_unused, **kwargs)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a list of all matches in the string. The matches may be overlapped\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mif overlapped is True. If one or more groups are present in the pattern,\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;124;03mreturn a list of groups; this will be a list of tuples if the pattern has\u001b[39;00m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03mmore than one group. Empty matches are included in the result.\"\"\"\u001b[39;00m\n\u001b[0;32m    337\u001b[0m pat \u001b[38;5;241m=\u001b[39m _compile(pattern, flags, ignore_unused, kwargs, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverlapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcurrent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["tokenized_billsum = split_dataset.map(preprocess_function, batched=True)"]},{"cell_type":"markdown","metadata":{},"source":["# Fine-tuning the model"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T16:24:24.212681Z","iopub.status.busy":"2023-11-16T16:24:24.212336Z","iopub.status.idle":"2023-11-16T16:24:24.319417Z","shell.execute_reply":"2023-11-16T16:24:24.318420Z","shell.execute_reply.started":"2023-11-16T16:24:24.212655Z"},"trusted":true},"outputs":[],"source":["from transformers import TrainingArguments\n","\n","# Define training arguments for the model\n","training_args = TrainingArguments(\n","    output_dir='./results',          # Directory to save model output and checkpoints\n","    num_train_epochs=2,              # Number of epochs to train the model\n","    per_device_train_batch_size=8,   # Batch size per device during training\n","    per_device_eval_batch_size=8,    # Batch size for evaluation\n","    warmup_steps=500,                # Number of warmup steps for learning rate scheduler\n","    weight_decay=0.01,               # Weight decay for regularization\n","    logging_dir='./logs',            # Directory to save logs\n","    logging_steps=10,                # Log metrics every specified number of steps\n","    evaluation_strategy=\"epoch\",     # Evaluation is done at the end of each epoch\n","    report_to='none'                 # Disables reporting to any online services (e.g., TensorBoard, WandB)\n",")"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T16:24:24.321034Z","iopub.status.busy":"2023-11-16T16:24:24.320698Z","iopub.status.idle":"2023-11-16T17:58:37.177020Z","shell.execute_reply":"2023-11-16T17:58:37.175977Z","shell.execute_reply.started":"2023-11-16T16:24:24.321006Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3678' max='3678' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3678/3678 1:33:56, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.099500</td>\n","      <td>0.086062</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.083400</td>\n","      <td>0.081724</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/plain":["TrainOutput(global_step=3678, training_loss=0.4837404892229399, metrics={'train_runtime': 5644.8729, 'train_samples_per_second': 10.423, 'train_steps_per_second': 0.652, 'total_flos': 1.793783686496256e+16, 'train_loss': 0.4837404892229399, 'epoch': 2.0})"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["# Initializing the Trainer object\n","trainer = Trainer(\n","    model=model,             # The model to be trained (e.g., our BART model)\n","    args=training_args,      # Training arguments specifying training parameters like learning rate, batch size, etc.\n","    train_dataset=train_dataset,  # The dataset to be used for training the model\n","    eval_dataset=valid_dataset    # The dataset to be used for evaluating the model during training\n",")\n","\n","# Starting the training process\n","trainer.train()"]},{"cell_type":"markdown","metadata":{},"source":["# Model Evaluation using Rogue Score"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T17:58:37.178920Z","iopub.status.busy":"2023-11-16T17:58:37.178516Z","iopub.status.idle":"2023-11-16T17:59:59.598975Z","shell.execute_reply":"2023-11-16T17:59:59.597908Z","shell.execute_reply.started":"2023-11-16T17:58:37.178884Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"90172bd1942d49e592513f1a207d2e27","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/2.16k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'rouge1': AggregateScore(low=Score(precision=0.5203167404161397, recall=0.454729290212834, fmeasure=0.4632587632485201), mid=Score(precision=0.5354479435805708, recall=0.46890642945251565, fmeasure=0.47534285466245074), high=Score(precision=0.5502350562403443, recall=0.4824408056039646, fmeasure=0.48742275414871145)), 'rouge2': AggregateScore(low=Score(precision=0.25078879710302293, recall=0.21609817018001448, fmeasure=0.22050781070275272), mid=Score(precision=0.26568774609184886, recall=0.2292050456292191, fmeasure=0.2331994917519589), high=Score(precision=0.2808212845633841, recall=0.24289826444917545, fmeasure=0.24596704167812236)), 'rougeL': AggregateScore(low=Score(precision=0.43189569859182625, recall=0.3784438094396151, fmeasure=0.38432840225294457), mid=Score(precision=0.4465577989373004, recall=0.39079956181403797, fmeasure=0.39648919210982875), high=Score(precision=0.46139814838987636, recall=0.4039602038430952, fmeasure=0.4090468688096221)), 'rougeLsum': AggregateScore(low=Score(precision=0.43240651966225446, recall=0.37708782318853007, fmeasure=0.3830899011510724), mid=Score(precision=0.44632278342320875, recall=0.39037924872253826, fmeasure=0.3960953437919044), high=Score(precision=0.46162203989167455, recall=0.40313163998239104, fmeasure=0.4075494148313833))}\n"]}],"source":["from datasets import load_metric\n","from torch.utils.data import DataLoader\n","\n","# Load the ROUGE metric for evaluation\n","rouge = load_metric('rouge')\n","\n","def generate_summaries(model, tokenizer, dataset, batch_size=8):\n","    \"\"\"\n","    Generate summaries using the provided model and tokenizer on the given dataset.\n","\n","    Args:\n","        model: The trained summarization model.\n","        tokenizer: Tokenizer associated with the model.\n","        dataset: Dataset for which summaries need to be generated.\n","        batch_size: Number of data samples to process in each batch.\n","\n","    Returns:\n","        summaries: Generated summaries by the model.\n","        references: Actual summaries from the dataset for comparison.\n","    \"\"\"\n","    # Set model to evaluation mode\n","    model.eval()\n","    summaries = []    # List to store generated summaries\n","    references = []   # List to store actual summaries\n","\n","    # Create a DataLoader for batch processing\n","    dataloader = DataLoader(dataset, batch_size=batch_size)\n","\n","    # Disabled gradient calculations for efficiency\n","    with torch.no_grad():\n","        for batch in dataloader:\n","            # Move input data to the same device as the model\n","            input_ids = batch['input_ids'].to(model.device)\n","            attention_mask = batch['attention_mask'].to(model.device)\n","\n","            # Generate summaries with the model\n","            outputs = model.generate(input_ids, attention_mask=attention_mask, max_length=2048, num_beams=2)\n","            batch_summaries = [tokenizer.decode(ids, skip_special_tokens=True) for ids in outputs]\n","\n","            # Append generated and actual summaries to the respective lists\n","            summaries.extend(batch_summaries)\n","            references.extend(batch['summary'])\n","\n","    return summaries, references\n","\n","# Generate summaries for the validation dataset\n","generated_summaries, actual_summaries = generate_summaries(model, tokenizer, valid_dataset, batch_size=8)\n","\n","# Compute and print the ROUGE score for evaluation\n","rouge_score = rouge.compute(predictions=generated_summaries, references=actual_summaries)\n","print(rouge_score)"]},{"cell_type":"markdown","metadata":{},"source":["### Displaying the Rouge scores to better understand the results"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T18:03:51.659121Z","iopub.status.busy":"2023-11-16T18:03:51.658647Z","iopub.status.idle":"2023-11-16T18:03:51.702328Z","shell.execute_reply":"2023-11-16T18:03:51.701251Z","shell.execute_reply.started":"2023-11-16T18:03:51.659089Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F-Measure</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">rouge1</th>\n","      <th>low</th>\n","      <td>0.5203</td>\n","      <td>0.4547</td>\n","      <td>0.4632</td>\n","    </tr>\n","    <tr>\n","      <th>mid</th>\n","      <td>0.5354</td>\n","      <td>0.4689</td>\n","      <td>0.4753</td>\n","    </tr>\n","    <tr>\n","      <th>high</th>\n","      <td>0.5502</td>\n","      <td>0.4824</td>\n","      <td>0.4874</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">rouge2</th>\n","      <th>low</th>\n","      <td>0.2507</td>\n","      <td>0.2160</td>\n","      <td>0.2205</td>\n","    </tr>\n","    <tr>\n","      <th>mid</th>\n","      <td>0.2656</td>\n","      <td>0.2292</td>\n","      <td>0.2331</td>\n","    </tr>\n","    <tr>\n","      <th>high</th>\n","      <td>0.2808</td>\n","      <td>0.2428</td>\n","      <td>0.2459</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">rougeL</th>\n","      <th>low</th>\n","      <td>0.4318</td>\n","      <td>0.3784</td>\n","      <td>0.3843</td>\n","    </tr>\n","    <tr>\n","      <th>mid</th>\n","      <td>0.4465</td>\n","      <td>0.3907</td>\n","      <td>0.3964</td>\n","    </tr>\n","    <tr>\n","      <th>high</th>\n","      <td>0.4613</td>\n","      <td>0.4039</td>\n","      <td>0.4090</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">rougeLsum</th>\n","      <th>low</th>\n","      <td>0.4324</td>\n","      <td>0.3770</td>\n","      <td>0.3830</td>\n","    </tr>\n","    <tr>\n","      <th>mid</th>\n","      <td>0.4463</td>\n","      <td>0.3903</td>\n","      <td>0.3960</td>\n","    </tr>\n","    <tr>\n","      <th>high</th>\n","      <td>0.4616</td>\n","      <td>0.4031</td>\n","      <td>0.4075</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                Precision  Recall  F-Measure\n","rouge1    low      0.5203  0.4547     0.4632\n","          mid      0.5354  0.4689     0.4753\n","          high     0.5502  0.4824     0.4874\n","rouge2    low      0.2507  0.2160     0.2205\n","          mid      0.2656  0.2292     0.2331\n","          high     0.2808  0.2428     0.2459\n","rougeL    low      0.4318  0.3784     0.3843\n","          mid      0.4465  0.3907     0.3964\n","          high     0.4613  0.4039     0.4090\n","rougeLsum low      0.4324  0.3770     0.3830\n","          mid      0.4463  0.3903     0.3960\n","          high     0.4616  0.4031     0.4075"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["rouge_scores = {\n","    'rouge1': {\n","        'low': {'precision': 0.5203, 'recall': 0.4547, 'fmeasure': 0.4632},\n","        'mid': {'precision': 0.5354, 'recall': 0.4689, 'fmeasure': 0.4753},\n","        'high': {'precision': 0.5502, 'recall': 0.4824, 'fmeasure': 0.4874}\n","    },\n","    'rouge2': {\n","        'low': {'precision': 0.2507, 'recall': 0.2160, 'fmeasure': 0.2205},\n","        'mid': {'precision': 0.2656, 'recall': 0.2292, 'fmeasure': 0.2331},\n","        'high': {'precision': 0.2808, 'recall': 0.2428, 'fmeasure': 0.2459}\n","    },\n","    'rougeL': {\n","        'low': {'precision': 0.4318, 'recall': 0.3784, 'fmeasure': 0.3843},\n","        'mid': {'precision': 0.4465, 'recall': 0.3907, 'fmeasure': 0.3964},\n","        'high': {'precision': 0.4613, 'recall': 0.4039, 'fmeasure': 0.4090}\n","    },\n","    'rougeLsum': {\n","        'low': {'precision': 0.4324, 'recall': 0.3770, 'fmeasure': 0.3830},\n","        'mid': {'precision': 0.4463, 'recall': 0.3903, 'fmeasure': 0.3960},\n","        'high': {'precision': 0.4616, 'recall': 0.4031, 'fmeasure': 0.4075}\n","    }\n","}\n","\n","# Convert the nested dictionary into a Pandas DataFrame\n","scores = pd.DataFrame.from_dict({(i, j): rouge_scores[i][j] \n","                            for i in rouge_scores.keys() \n","                            for j in rouge_scores[i].keys()},\n","                            orient='index')\n","\n","# Set column names for readability\n","scores.columns = ['Precision', 'Recall', 'F-Measure']\n","\n","# Display the DataFrame\n","scores"]},{"cell_type":"markdown","metadata":{},"source":["### Let's test the model on a conversation using input "]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T18:04:03.078869Z","iopub.status.busy":"2023-11-16T18:04:03.078461Z","iopub.status.idle":"2023-11-16T18:04:03.089470Z","shell.execute_reply":"2023-11-16T18:04:03.088511Z","shell.execute_reply.started":"2023-11-16T18:04:03.078826Z"},"trusted":true},"outputs":[],"source":["# Check if CUDA (GPU support) is available and choose the device accordingly\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Move the model to the chosen device\n","model = model.to(device)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T18:04:05.870343Z","iopub.status.busy":"2023-11-16T18:04:05.869492Z","iopub.status.idle":"2023-11-16T18:04:05.876427Z","shell.execute_reply":"2023-11-16T18:04:05.875524Z","shell.execute_reply.started":"2023-11-16T18:04:05.870307Z"},"trusted":true},"outputs":[],"source":["def summarize_text(text, max_length=5000):\n","    \"\"\"\n","    Generates a summary for the given text using a pre-trained model.\n","\n","    Args:\n","        text (str): The text to be summarized.\n","        max_length (int): The maximum length of the input text for the model.\n","\n","    Returns:\n","        str: The generated summary of the input text.\n","    \"\"\"\n","    # Encode the input text using the tokenizer. The 'pt' indicates PyTorch tensors.\n","    inputs = tokenizer.encode(text, return_tensors=\"pt\", max_length=max_length, truncation=False)\n","    \n","    # Move the encoded text to the same device as the model (e.g., GPU or CPU)\n","    inputs = inputs.to(device)\n","\n","    # Generate summary IDs with the model. num_beams controls the beam search width.\n","    # early_stopping is set to False for a thorough search, though it can be set to True for faster results.\n","    summary_ids = model.generate(inputs, max_length=2000, num_beams=30, early_stopping=False)\n","\n","    # Decode the generated IDs back to text, skipping special tokens like padding or EOS.\n","    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","\n","    # Return the generated summary\n","    return summary"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T18:24:48.340326Z","iopub.status.busy":"2023-11-16T18:24:48.339528Z","iopub.status.idle":"2023-11-16T18:24:50.922034Z","shell.execute_reply":"2023-11-16T18:24:50.921055Z","shell.execute_reply.started":"2023-11-16T18:24:48.340291Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter the text:  Web Developer (You): Hey, I just launched a new website with some exciting features. Would you like to check it out? Machine Learning Enthusiast: That sounds interesting! I'd love to see how you've integrated machine learning into it. Computer Science Student: Speaking of machine learning, have you heard about the latest breakthroughs in natural language processing? Science Enthusiast: Yes, I've been following those developments closely. It's amazing how AI is transforming language understanding. Mathematics Enthusiast: Absolutely! The mathematical foundations of deep learning play a crucial role in these advancements. News Enthusiast: By the way, did you catch the latest headlines? There's a lot happening in the world right now. Web Developer (You): I did! In fact, my website can recommend personalized news articles based on user preferences. Clinical Medical Assistant: That's impressive! Speaking of recommendations, have you worked on any projects related to healthcare? Machine Learning Enthusiast: Yes, I did a project on hybrid acoustic and facial emotion recognition, which could have applications in mental health. Computer Science Student: That's fascinating! It's incredible how our interests and expertise intersect across various fields of study and technology.\n"]},{"name":"stdout","output_type":"stream","text":["Enter the text: Web Developer (You): Hey, I just launched a new website with some exciting features. Would you like to check it out? Machine Learning Enthusiast: That sounds interesting! I'd love to see how you've integrated machine learning into it. Computer Science Student: Speaking of machine learning, have you heard about the latest breakthroughs in natural language processing? Science Enthusiast: Yes, I've been following those developments closely. It's amazing how AI is transforming language understanding. Mathematics Enthusiast: Absolutely! The mathematical foundations of deep learning play a crucial role in these advancements. News Enthusiast: By the way, did you catch the latest headlines? There's a lot happening in the world right now. Web Developer (You): I did! In fact, my website can recommend personalized news articles based on user preferences. Clinical Medical Assistant: That's impressive! Speaking of recommendations, have you worked on any projects related to healthcare? Machine Learning Enthusiast: Yes, I did a project on hybrid acoustic and facial emotion recognition, which could have applications in mental health. Computer Science Student: That's fascinating! It's incredible how our interests and expertise intersect across various fields of study and technology.\n","\n","Web Developer introduces his new website to Computer Science Student, who is interested in the latest breakthroughs in natural language processing. Science Enthusiast thinks it's amazing how their interests and expertise intersect across various fields of study and technology.\n"]}],"source":["# Prompt the user to enter text for summarization\n","text = input('Enter the text: ')\n","print()\n","\n","# Call the summarize_text function to generate a summary of the input text\n","summary = summarize_text(text)\n","\n","# Print the generated summary\n","print(summary)"]},{"cell_type":"markdown","metadata":{},"source":["## Conclusion\n","\n","In this notebook, I fine-tuned the BART Base model for summarizing chat conversations. The model showed promising performance, especially in capturing the essence of dialogues. The findings revealed the model's strengths and areas of improvement as follows:\n","\n","1. **Consistency in Capturing Key Points:** The ROUGE-1 scores, with a high precision of 0.5502 and recall of 0.4824, indicate that the model is consistently capturing key points from the conversations. This suggests that for most of the chat content, the generated summaries were aligned well with the essential topics.\n","\n","\n","2. **Complex Relationships and Nuances:** The ROUGE-2 scores, particularly the high precision of 0.2808 and recall of 0.2428, reflect the model's ability to grasp more complex relationships and nuances in the conversations. While lower than ROUGE-1, these scores are indicative of the model's potential in understanding subtleties in dialogues.\n","\n","\n","3. **Summary Length and Relevance:** The ROUGE-L and ROUGE-Lsum scores, with a high precision of around 0.4613 and a recall of approximately 0.4039, demonstrate the model's capability in maintaining the length and relevance of the original dialogues in the summaries.\n","\n","\n","\n","- While the model shows effectiveness in summarizing chat conversations, there is room for improvement, particularly in capturing more intricate details and subtleties, as suggested by the ROUGE-2 scores.\n","\n","I welcome any feedback or questions in the comments and am open to collaborations on similar projects. For further discussions or networking opportunities, feel free to connect with me on [LinkedIn](https://www.linkedin.com/in/farneet-singh-6b155b208/)."]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":3995670,"sourceId":6956480,"sourceType":"datasetVersion"},{"datasetId":4005809,"sourceId":6971920,"sourceType":"datasetVersion"},{"datasetId":4008786,"sourceId":6976321,"sourceType":"datasetVersion"}],"dockerImageVersionId":30588,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
